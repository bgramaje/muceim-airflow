# Optimizaci√≥n de Memoria - Airflow OOM (SIGKILL -9)

## üìä Problema Identificado
- **Error**: `CRITICAL - Process terminated by signal. SIGKILL -9`
- **Causa**: Pool con 15 slots provocando 15 tareas paralelas, cada una cargando CSVs/JSONs completos en memoria
- **S√≠ntoma**: DuckDB + Pandas + GeoPandas sin l√≠mites de memoria

## ‚úÖ Soluciones Implementadas

### 1. ‚úì Reducci√≥n de Paralelismo (CR√çTICO)
```yaml
# airflow_settings.yaml
od_pool: 15 slots ‚Üí 3 slots
```
**Impacto**: Reduce de 15 tareas paralelas a solo 3 simult√°neas
- Menos presi√≥n sobre memoria
- Las tareas toman m√°s tiempo pero no fallan por OOM

### 2. ‚úì L√≠mites de Memoria en DuckDB (utils.py)
```sql
SET max_memory='2GB';              -- M√°ximo 2GB por conexi√≥n
SET threads=2;                      -- Reduce paralelismo interno (era ilimitado)
SET memory_limit='2GB';             -- L√≠mite estricto
SET max_temp_directory_size='8GB';  -- Temp reducido de 40GB a 8GB
```

### 3. üìã Pasos Adicionales Recomendados

#### A. Configurar l√≠mites en Docker/Kubernetes (si aplica)
```dockerfile
# En tu Dockerfile o docker-compose
environment:
  - AIRFLOW__CORE__MAX_TASK_INSTANCES_PER_DAGRUN=3
  - AIRFLOW__CORE__DAG_FILE_PROCESSOR_TIMEOUT=600
  - AIRFLOW__CORE__KILLED_TASK_CLEANUP_TIME=60
```

#### B. Aumentar timeout de tareas
En `dags/main.py` o en cada DAG:
```python
with DAG(..., execution_timeout=timedelta(hours=2)):
```

#### C. Monitorear memoria en ejecuci√≥n
```bash
# Terminal 1: Ver estado de tareas
docker stats airflow-worker

# Terminal 2: Ver logs
tail -f logs/dag_id/task_id/attempt_*.log | grep -i "memory\|killed"
```

## üîç Alternativas si el Problema Persiste

### Opci√≥n A: Chunked Processing (Streaming)
Modificar `merge_from_csv()` para procesar datos en bloques de 10K filas:
```python
def merge_from_csv_chunked(table_name, url, chunk_size=10000):
    """Lee CSV en chunks en lugar de cargar todo a la vez."""
    for chunk in pd.read_csv(url, chunksize=chunk_size):
        con.execute(f"INSERT INTO {table_name} SELECT * FROM chunk")
```

### Opci√≥n B: Procesar URLs secuencialmente
Cambiar de `dynamic_task_map()` a loop secuencial:
```python
# En lugar de paralelo por URL
for url in urls:
    BRONZE_mitma_od_insert(url, zone_type)  # Una a una
```

### Opci√≥n C: Usar Spark en lugar de Pandas (si escalas)
Para vol√∫menes muy grandes, Spark maneja OOM mejor.

## üß™ C√≥mo Validar los Cambios

1. **Reducir dataset para testing**:
   ```python
   # En dags/main.py cambiar temporalmente:
   start_date = "2025-12-01"
   end_date = "2025-12-02"  # Solo 1 d√≠a en lugar de rango completo
   ```

2. **Ejecutar DAG con pruebas**:
   ```bash
   astro dev restart
   # Ve a http://localhost:8080 y dispara manualmente
   ```

3. **Monitorear en tiempo real**:
   ```bash
   watch -n 1 'docker stats airflow-worker --no-stream | tail -1'
   ```

## üìà M√©tricas Esperadas

| M√©trica | Antes | Despu√©s |
|---------|-------|---------|
| Tareas Paralelas | 15 | 3 |
| Memoria por Tarea | ~800MB | ~300-500MB |
| Tiempo Total DAG | ~5 min | ~15-20 min |
| OOM Errors | Frecuente | Raramente |

## üöÄ Pr√≥ximos Pasos

Si persiste el error despu√©s de estos cambios:

1. Revisar logs detallados:
   ```bash
   grep -i "memory\|killed\|oom" logs/**/*.log
   ```

2. Aumentar recursos del contenedor Docker:
   ```bash
   # En docker-compose o config
   memory: 4GB  # Aumentar si es posible
   ```

3. Considerar split de DAG:
   - Grupo 1: MITMA OD (distritos)
   - Grupo 2: MITMA OD (municipios)
   - Grupo 3: MITMA OD (gau)
   - (Ejecutan secuencialmente, no simult√°neamente)

---

**√öltima actualizaci√≥n**: 2025-12-16
**Estado**: ‚úÖ Cambios implementados - Pendiente validaci√≥n en producci√≥n
