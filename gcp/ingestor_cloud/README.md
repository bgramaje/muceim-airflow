# Cloud Run Job: insert-ducklake

Este Cloud Run Job descarga CSVs desde URLs y los inserta en DuckDB usando el ancho de banda de Google Cloud.

## Estructura

```
cloud_run_job/
‚îú‚îÄ‚îÄ main.py           # C√≥digo principal del job
‚îú‚îÄ‚îÄ Dockerfile        # Imagen Docker para el job
‚îú‚îÄ‚îÄ requirements.txt  # Dependencias Python
‚îî‚îÄ‚îÄ README.md         # Esta documentaci√≥n
```

## Despliegue

### ‚ö†Ô∏è IMPORTANTE: Crear repositorio de Artifact Registry y dar permisos

Antes de ejecutar el build, necesitas:

#### 1. Crear el repositorio de Artifact Registry

1. Ve a **Artifact Registry** > **Repositories**: https://console.cloud.google.com/artifacts
2. Haz clic en **CREATE REPOSITORY**
3. Configuraci√≥n:
   - **Name**: `cloud-run-source-deploy`
   - **Format**: Docker
   - **Mode**: Standard
   - **Region**: `europe-southwest1` (Madrid)
4. Haz clic en **CREATE**

#### 2. Dar permisos a Cloud Build Service Account

La Service Account de Cloud Build necesita permisos para subir im√°genes. Hazlo desde la interfaz:

1. Ve al repositorio que acabas de crear: `cloud-run-source-deploy`
2. Haz clic en la pesta√±a **PERMISSIONS**
3. Haz clic en **ADD PRINCIPAL**
4. En **New principals**, busca: `PROJECT_NUMBER@cloudbuild.gserviceaccount.com`
   - Para encontrar tu PROJECT_NUMBER: Ve a **IAM & Admin** > **Settings** y copia el "Project number"
   - Ejemplo: `123456789012@cloudbuild.gserviceaccount.com`
5. En **Role**, selecciona: **Artifact Registry Writer**
6. Haz clic en **SAVE**

**Alternativa r√°pida**: Si no encuentras el PROJECT_NUMBER, puedes dar permisos a nivel de proyecto:
- Ve a **IAM & Admin** > **IAM**
- Busca la Service Account de Cloud Build (formato: `PROJECT_NUMBER@cloudbuild.gserviceaccount.com`)
- Agrega el rol: **Artifact Registry Writer** a nivel de proyecto

**Alternativa**: Si prefieres usar otro nombre de repositorio, actualiza `cloudbuild.yaml` y reemplaza `cloud-run-source-deploy` con tu nombre.

---

Tienes dos opciones para construir la imagen: usar la interfaz web (m√°s f√°cil, sin CLI) o usar gcloud CLI.

### Opci√≥n A: Desde la Interfaz Web (Recomendado - No requiere CLI)

#### 1. Subir el c√≥digo a un repositorio

Primero, necesitas tener el c√≥digo en un repositorio accesible:
- GitHub
- GitLab
- O cualquier repositorio Git

#### 2. Construir la imagen con Cloud Build

1. Ve a **Cloud Build** > **Triggers**: https://console.cloud.google.com/cloud-build/triggers
2. Haz clic en **CREATE TRIGGER**
3. Configuraci√≥n:
   - **Name**: `build-insert-ducklake`
   - **Event**: Push to a branch
   - **Source**: Conecta tu repositorio (GitHub/GitLab)
   - **Branch**: `main` o `master`
   - **Configuration**: Cloud Build configuration file (yaml)
   - **Location**: `cloud_run_job/cloudbuild.yaml` (crea este archivo, ver abajo)
4. Haz clic en **CREATE**

**Nota**: El archivo `cloud_run_job/cloudbuild.yaml` ya est√° creado y configurado para usar Artifact Registry.

5. Haz push a tu repositorio para activar el build

#### 3. Crear el Cloud Run Job desde la interfaz

1. Ve a **Cloud Run** > **Jobs**: https://console.cloud.google.com/run/jobs
2. Haz clic en **CREATE JOB**
3. Configuraci√≥n:
   - **Job name**: `insert-ducklake`
   - **Region**: `europe-southwest1` (Madrid)
   - **Container image URL**: `europe-southwest1-docker.pkg.dev/muceim-bigdata/cloud-run-source-deploy/insert-ducklake:latest`
   - **CPU**: 2 (o m√°s seg√∫n necesites)
   - **Memory**: 4Gi (o m√°s seg√∫n necesites)
   - **Timeout**: 3600s (1 hora) o m√°s
   - **Max retries**: 0 (o 1-2 si quieres reintentos)

4. **Variables de entorno** (se pasan desde Airflow, pero puedes definir defaults):
   - `POSTGRES_HOST`: (tu host de PostgreSQL)
   - `POSTGRES_PORT`: `5432`
   - `POSTGRES_DB`: (tu base de datos)
   - `POSTGRES_USER`: (tu usuario)
   - `POSTGRES_PASSWORD`: (tu contrase√±a) - **Usa Secret Manager**
   - `S3_ENDPOINT`: (tu endpoint RustFS, ej: `rustfs:9000`)
   - `RUSTFS_USER`: (tu usuario RustFS)
   - `RUSTFS_PASSWORD`: (tu contrase√±a RustFS) - **Usa Secret Manager**
   - `RUSTFS_BUCKET`: `mitma`
   - `RUSTFS_SSL`: `false` o `true`

5. **Secrets** (recomendado para contrase√±as):
   - Ve a **Secrets** y agrega:
     - `POSTGRES_PASSWORD` ‚Üí Secret Manager secret
     - `RUSTFS_PASSWORD` ‚Üí Secret Manager secret

6. **VPC Connector** (si PostgreSQL/RustFS est√°n en una VPC):
   - Si tus recursos est√°n en una VPC privada, configura un VPC Connector
   - ‚ö†Ô∏è **IMPORTANTE - Acceso a Internet**: Si configuras un VPC Connector, tambi√©n debes configurar el **VPC egress**:
     - **VPC egress**: Selecciona **"All traffic"** o **"Private ranges"** seg√∫n tus necesidades
     - Si seleccionas **"All traffic"**, el tr√°fico a internet pasar√° por la VPC (necesitar√°s NAT Gateway)
     - Si solo necesitas acceso a recursos privados, selecciona **"Private ranges"** y mant√©n el acceso directo a internet p√∫blico
     - Si no configuras esto correctamente, el job **NO podr√° acceder a internet** (por ejemplo, para descargar CSVs desde URLs p√∫blicas)
     - Ver m√°s detalles en la secci√≥n "‚ö†Ô∏è Configuraci√≥n de Red y Acceso a Internet" m√°s abajo

7. Haz clic en **CREATE**

### 3. Permisos

Aseg√∫rate de que la Service Account de Airflow tenga:
- `roles/run.invoker` - Para ejecutar el job

```bash
gcloud projects add-iam-policy-binding muceim-bigdata \
  --member="serviceAccount:muceim-cloud-runner@muceim-bigdata.iam.gserviceaccount.com" \
  --role="roles/run.invoker"
```

## Uso desde Airflow

El job se ejecuta autom√°ticamente desde Airflow usando la funci√≥n `exec_gcp_ducklake_ingestor()` en `dags/utils/gcp.py`.

Las variables de entorno `TABLE_NAME`, `URL`, y `ZONE_TYPE` se pasan autom√°ticamente desde Airflow.

## ‚ö†Ô∏è Configuraci√≥n de Acceso a Internet

**NOTA**: Si ves `curl exit code: 0` pero recibes `HTTP 500` u otros c√≥digos de error HTTP, Cloud Run **S√ç tiene acceso a internet**. El problema es que el servidor remoto est√° fallando, no la configuraci√≥n de Cloud Run.

Si tu Cloud Run job no puede acceder a internet (por ejemplo, `curl` falla con errores de conexi√≥n o DNS):

### Verificaci√≥n Inicial

Primero, verifica si tienes VPC Connector configurado:

```bash
gcloud run jobs describe insert-ducklake \
  --region=europe-southwest1 \
  --format="get(template.template.vpcAccess.connector)"
```

- Si devuelve un valor (nombre de connector): Tienes VPC configurado ‚Üí ve a "Soluci√≥n A"
- Si est√° vac√≠o: No tienes VPC ‚Üí ve a "Soluci√≥n B"

---

### Soluci√≥n A: Si tienes VPC Connector configurado

Si tus recursos est√°n en servicios externos accesibles por internet (no en una VPC privada de Google Cloud), **NO necesitas VPC Connector**. Remu√©velo:

#### Desde la Consola de Google Cloud

1. Ve a [Cloud Run Jobs](https://console.cloud.google.com/run/jobs)
2. Haz clic en tu job (`insert-ducklake`)
3. Haz clic en **EDIT**
4. Expande **Networking, Security, Limits & Admin**
5. En **VPC connector**, cambia a **"No VPC connector"**
6. Haz clic en **SAVE**

#### Desde l√≠nea de comandos

```bash
gcloud run jobs update insert-ducklake \
  --region=europe-southwest1 \
  --clear-vpc-connector
```

---

### Soluci√≥n B: Si NO tienes VPC Connector (y a√∫n as√≠ no funciona) üîç

**Si verificaste que `vpcAccess: null` y a√∫n as√≠ no funciona**, sigue estos pasos de diagn√≥stico:

#### 1. Organization Policies

Revisa si hay pol√≠ticas de organizaci√≥n que bloqueen el acceso a internet:

```bash
# Verificar constraints de red
gcloud resource-manager org-policies list \
  --project=TU_PROJECT_ID \
  --format="table(constraint)"
```

Busca pol√≠ticas relacionadas con `compute.vmCanIpForward` o `compute.restrictVpcPeering`.

#### 2. Firewall Rules

Verifica que no haya reglas de firewall bloqueando el tr√°fico saliente (aunque Cloud Run no deber√≠a verse afectado por firewall rules de VPC).

#### 3. Service Account Permissions

Aseg√∫rate de que la Service Account del job tenga los permisos necesarios (aunque esto no deber√≠a afectar el acceso a internet).

#### 4. Revisar Logs del Job ‚ö†Ô∏è IMPORTANTE

Revisa los logs del Cloud Run job para ver el error espec√≠fico que est√° dando `curl`:

```bash
# Ver logs del job
gcloud logging read "resource.type=cloud_run_job AND resource.labels.job_name=insert-ducklake" \
  --limit=50 \
  --format="table(timestamp,textPayload)"

# O filtrar solo errores de curl
gcloud logging read "resource.type=cloud_run_job AND resource.labels.job_name=insert-ducklake AND textPayload=~\"curl\"" \
  --limit=20 \
  --format="table(timestamp,textPayload)"
```

O desde la consola: [Cloud Run Jobs > insert-ducklake > Logs](https://console.cloud.google.com/run/jobs)

**Busca estos errores comunes:**
- `curl: (6) Could not resolve host` ‚Üí Problema de DNS
- `curl: (7) Failed to connect` ‚Üí No puede conectar (firewall/proxy)
- `curl: (28) Timeout` ‚Üí Timeout despu√©s de 30 segundos
- `curl: (35) SSL connect error` ‚Üí Problema con SSL/TLS

#### 5. Probar con un job de prueba simple

Crea un job de prueba m√≠nimo para verificar el acceso a internet:

```python
import subprocess
result = subprocess.run(["curl", "-I", "https://www.google.com"], capture_output=True, text=True)
print(result.stdout)
print(result.stderr)
```

---

### Si necesitas VPC Connector (solo si tus recursos est√°n en una VPC privada)

Si necesitas acceder a recursos privados en tu VPC **Y** tambi√©n necesitas internet:

1. Ve a la consola
2. En **VPC egress**, selecciona **"Private ranges"**
3. Esto permite: acceso a internet p√∫blico directo + acceso a rangos privados v√≠a VPC

O desde l√≠nea de comandos:
```bash
gcloud run jobs update insert-ducklake \
  --region=europe-southwest1 \
  --vpc-egress=private-ranges-only
```

## Testing local

Para probar localmente antes de desplegar:

```bash
# Instalar dependencias
pip install -r requirements.txt

# Configurar variables de entorno
export TABLE_NAME=mitma_od_municipios
export URL=https://ejemplo.com/data.csv
export ZONE_TYPE=municipios
export POSTGRES_HOST=...
# ... resto de variables

# Ejecutar
python main.py
```

